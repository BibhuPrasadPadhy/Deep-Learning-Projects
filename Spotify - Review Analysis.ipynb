{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4224e582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BIBHU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\BIBHU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns \n",
    "import contractions\n",
    "import tensorflow as tf\n",
    "\n",
    "import spacy\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.util import ngrams\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import swifter\n",
    "import re\n",
    "pd.options.display.max_rows = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13fcc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lem = WordNetLemmatizer()\n",
    "    return \" \".join([lem.lemmatize(i) for i in text.split()])\n",
    "\n",
    "def contract_fix(text):\n",
    "    return \" \".join([contractions.fix(word) for word in text.split()])\n",
    "\n",
    "def word_freq_func(corpus):\n",
    "    word_freq = dict()\n",
    "    for token in corpus.split():\n",
    "        if token not in word_freq.keys():\n",
    "            word_freq[token]=1\n",
    "        else:\n",
    "            word_freq[token]+= 1\n",
    "        \n",
    "    word_freq_df = pd.DataFrame({'words':word_freq.keys(),'values':word_freq.values()})\n",
    "    word_freq_df = word_freq_df.sort_values(by='values',ascending=False)\n",
    "    \n",
    "    return word_freq_df\n",
    "\n",
    "def noise_removal(text):\n",
    "    return \" \".join(i for i in text.split() if i not in stop_words)\n",
    "\n",
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    fig = plt.figure(figsize=(25, 17), dpi=80)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.box(False)\n",
    "    plt.show()\n",
    "    plt.close() \n",
    "    \n",
    "def predict_sentiment_textblob(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return -1\n",
    "    elif score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def predict_sentiment_vader(text):\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "    return sentiment.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc777577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('reviews.csv')\n",
    "df = df_original.copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d017f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61594, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66291e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_submitted</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total_thumbsup</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61594</td>\n",
       "      <td>61594</td>\n",
       "      <td>61594.000000</td>\n",
       "      <td>61594.000000</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>61300</td>\n",
       "      <td>61356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2022-03-08 18:49:19</td>\n",
       "      <td>Too many ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey, sorry to hear that. If you haven't tried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.155989</td>\n",
       "      <td>7.649381</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.673285</td>\n",
       "      <td>89.323143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8195.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time_submitted        Review        Rating  Total_thumbsup  \\\n",
       "count                 61594         61594  61594.000000    61594.000000   \n",
       "unique                61300         61356           NaN             NaN   \n",
       "top     2022-03-08 18:49:19  Too many ads           NaN             NaN   \n",
       "freq                      4            36           NaN             NaN   \n",
       "mean                    NaN           NaN      3.155989        7.649381   \n",
       "std                     NaN           NaN      1.673285       89.323143   \n",
       "min                     NaN           NaN      1.000000        0.000000   \n",
       "25%                     NaN           NaN      1.000000        0.000000   \n",
       "50%                     NaN           NaN      3.000000        0.000000   \n",
       "75%                     NaN           NaN      5.000000        1.000000   \n",
       "max                     NaN           NaN      5.000000     8195.000000   \n",
       "\n",
       "                                                    Reply  \n",
       "count                                                 216  \n",
       "unique                                                180  \n",
       "top     Hey, sorry to hear that. If you haven't tried ...  \n",
       "freq                                                    7  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43cc19c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time_submitted        0\n",
       "Review                0\n",
       "Rating                0\n",
       "Total_thumbsup        0\n",
       "Reply             61378\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247888d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Reply','Time_submitted'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d8e62",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "##### Converting App Rating to Sentiments - 1,2 = Negative , 3 = Neutral, 4,5 = Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75ea44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Rating'].apply(lambda x : -1 if x in range(1,3) else (1 if x in range(4,6) else 0))\n",
    "df = df.drop(['Rating','Total_thumbsup'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2efffe7",
   "metadata": {},
   "source": [
    "#### Pre-Processing Reviews & make them model ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa46796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7085eb10f304ef787afcd9495312ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2715d5745ec4a5d8ba56de8ed77c47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fc2fe104534727939d733166603994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Review_Contraction_Fixed'] = df['Review'].swifter.apply(contract_fix)\n",
    "df['Review_Cleaned'] = df['Review_Contraction_Fixed'].swifter.apply(lambda x : re.sub('[^a-zA-Z]',' ',x))\n",
    "df['Review_Cleaned_lemma'] = df['Review_Cleaned'].swifter.apply(lemmatization)\n",
    "df['Review_Cleaned_lemma'] = df['Review_Cleaned_lemma'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5e281",
   "metadata": {},
   "source": [
    "#### Creating the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c90a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(df['Review_Cleaned_lemma'])\n",
    "vocab = list(set(corpus.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641fb0dd",
   "metadata": {},
   "source": [
    "#### Creating Word Frequency Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0108f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df = word_freq_func(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08127f24",
   "metadata": {},
   "source": [
    "#### Creating custom stop words of len=1,2 and removing 'no' from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4041e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = word_freq_df[word_freq_df['words'].str.len() < 3].words.to_list()\n",
    "stop_words.remove('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca850a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9654c6922c4fdf8337f569e7b1516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Review_Cleaned_lemma_noise_rm'] = df['Review_Cleaned_lemma'].swifter.apply(noise_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db231a13",
   "metadata": {},
   "source": [
    "#### Defining X & Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e946ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Review_Cleaned_lemma_noise_rm']\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb999a38",
   "metadata": {},
   "source": [
    "#### Using TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1610257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d3cca83cf04a73a217cffb7976a234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment_Textblob']= df['Review_Cleaned_lemma_noise_rm'].swifter.apply(predict_sentiment_textblob)\n",
    "df['Sentiment_Textblob_Label']= df['Sentiment_Textblob'].swifter.apply(getAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c98373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.42      0.54     24771\n",
      "     Neutral       0.13      0.13      0.13      6886\n",
      "    Positive       0.65      0.88      0.75     29937\n",
      "\n",
      "    accuracy                           0.61     61594\n",
      "   macro avg       0.51      0.48      0.47     61594\n",
      "weighted avg       0.63      0.61      0.59     61594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,auc,roc_auc_score,accuracy_score\n",
    "target_names = ['Negative', 'Neutral', 'Positive']\n",
    "print(classification_report(df['Sentiment'],df['Sentiment_Textblob_Label'],target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf25d3",
   "metadata": {},
   "source": [
    "###### Conclusiong : The TextBlob based sentiment predictor words well for Positive class as compared to Negative class but fails miserably to classify Neutral class\n",
    "\n",
    "###### Results can be improved changing the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381f422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
